# VLM Benchmarks

## General Benchmark Sites
* [MMMU Benchmark](https://mmmu-benchmark.github.io)
* [LM Arena](https://lmarena.ai)
* [OpenCompass](https://rank.opencompass.org.cn/home) (or [Hugging Face Leaderboard](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard))
* [Vision Checkup](https://visioncheckup.com/)
* [Roboflow Playground Leaderboard](https://playground.roboflow.com/leaderboard)

## VideoQA Benchmarks
* [MVBench](https://paperswithcode.com/dataset/mvbench)
* [VideoMME](https://video-mme.github.io/home_page.html)
* [TVBench](https://github.com/daniel-cores/tvbench)
* [Action-Atlas](https://mrsalehi.github.io/action-atlas/)
* [ShareGPT4Video](https://sharegpt4video.github.io/)
* [VideoEval-Pro](https://github.com/TIGER-AI-Lab/VideoEval-Pro)
* [OpenCV - Top VLM Evaluation Metrics for Optimal Performance Analysis](https://learnopencv.com/vlm-evaluation-metrics/)
